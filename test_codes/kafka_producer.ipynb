{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kafka\n",
    "import logging\n",
    "import asyncio\n",
    "#from zeppelin.notebook.utils.crypto_producer import CryptoProducer\n",
    "consumer = kafka.KafkaConsumer(group_id='check', bootstrap_servers=['localhost:9094'])\n",
    "consumer.topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9094')\n",
    "producer.send('btc', b'Hello, Kafka!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = CryptoProducer(\n",
    "  kafka_topic='btc',\n",
    "  kafka_server='localhost:9094',\n",
    "  start_time='2024-12-03 20:03:00'\n",
    ")\n",
    "\n",
    "cl.feed_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _produce_message_async(self, producer, topic, messages, key):\n",
    "\n",
    "    def on_send_success(record_metadata):\n",
    "      print(record_metadata.topic)\n",
    "      print(record_metadata.partition)\n",
    "      print(record_metadata.offset)\n",
    "\n",
    "    def on_send_error(excp):\n",
    "      logging.error('Error sending message', exc_info=excp)\n",
    "\n",
    "    futures = []\n",
    "    for message in messages:\n",
    "      future = producer.send(topic, key=message[key], value=message)\n",
    "      future.add_callback(on_send_success)\n",
    "      future.add_errback(on_send_error)\n",
    "      futures.append(future)\n",
    "\n",
    "    await asyncio.gather(*[asyncio.get_event_loop().run_in_executor(None, future.get) for future in futures])\n",
    "\n",
    "    producer.flush()\n",
    "    producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import requests as r\n",
    "import asyncio\n",
    "import aiokafka\n",
    "import kafka\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "\n",
    "class CryptoProducer:\n",
    "\n",
    "  format_str = '%Y-%m-%d %H:%M:%S'\n",
    "  schema = ['Timestamp', 'Low', 'High', 'Open', 'Close', 'Volume']\n",
    "  \n",
    "  def __init__(\n",
    "    self,\n",
    "    kafka_topic: str = None,\n",
    "    kafka_server: str = None,\n",
    "    start_time: str = None,\n",
    "    end_time: str = None,\n",
    "    granularity: int = 60,\n",
    "    symbol: str = None,\n",
    "    window: int = 5,\n",
    "    buffer: int = 60,\n",
    "    mode: str = 'sync',\n",
    "  ):\n",
    "    self.kafka_topic = kafka_topic\n",
    "    self.kafka_server = kafka_server\n",
    "    self.granularity = granularity\n",
    "    self.symbol = symbol\n",
    "    self.window = window\n",
    "    self.start_time = start_time\n",
    "    self.end_time = end_time\n",
    "    self.buffer = buffer\n",
    "    self.mode = mode\n",
    "\n",
    "    self.is_running = False\n",
    "\n",
    "    if not end_time:\n",
    "      self.end_time = datetime.utcnow().strftime(self.format_str)\n",
    "\n",
    "    self.producer = kafka.KafkaProducer(\n",
    "      bootstrap_servers=self.kafka_server, \n",
    "      value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8'),\n",
    "      key_serializer=lambda k: k.encode('utf-8')\n",
    "    )\n",
    "\n",
    "    self.aio_producer = None\n",
    "\n",
    "  def _get_data(self, start_time, end_time):\n",
    "    url = f'https://api.exchange.coinbase.com/products/{self.symbol}/candles?granularity={self.granularity}&start={start_time}&end={end_time}'\n",
    "    return r.get(url).json()\n",
    "  \n",
    "  def _break_time_range(self, start_time, end_time):\n",
    "    start = datetime.strptime(start_time, self.format_str)\n",
    "    end = datetime.strptime(end_time, self.format_str)\n",
    "    intervals = []\n",
    "\n",
    "    while start < end:\n",
    "      current_end = start + timedelta(hours=self.window)\n",
    "      if current_end > end:\n",
    "        current_end = end\n",
    "      intervals.append((start.strftime(self.format_str), current_end.strftime(self.format_str)))\n",
    "      start = current_end\n",
    "    \n",
    "    return intervals\n",
    "  \n",
    "  def _transform_data(self, data):\n",
    "    return dict(\n",
    "      [\n",
    "        (\n",
    "          col,\n",
    "          datetime.utcfromtimestamp(val)\n",
    "        )\n",
    "        if col == 'Timestamp' else (col, float(val)) for col, val in zip(self.schema, data)\n",
    "      ]\n",
    "    )\n",
    "  \n",
    "  def _on_send_success(self, record_metadata):\n",
    "    logging.info(record_metadata.topic)\n",
    "    logging.info(record_metadata.partition)\n",
    "    logging.info(record_metadata.offset)\n",
    "\n",
    "  def _on_send_error(self, excp):\n",
    "    logging.error('Error sending message', exc_info=excp)\n",
    "\n",
    "  def _feed_stream(self):\n",
    "\n",
    "    self.is_running = True\n",
    "    last = None\n",
    "    \n",
    "    try:\n",
    "      while self.is_running:\n",
    "        # Set data interval\n",
    "        intervals = self._break_time_range(self.start_time, self.end_time)\n",
    "        print(intervals)\n",
    "\n",
    "        # Get data for the interval\n",
    "        for interval in intervals:\n",
    "          data = self._get_data(interval[0], interval[1])\n",
    "          data = sorted(data, key=lambda x: x[0])\n",
    "          for row in data:\n",
    "            event = self._transform_data(row)\n",
    "            event_timestamp = event['Timestamp'].strftime(self.format_str)\n",
    "            if not last or event_timestamp > self.start_time:\n",
    "              self.producer.send(self.kafka_topic, key=event_timestamp, value=event).add_callback(self._on_send_success).add_errback(self._on_send_error)\n",
    "              last = event_timestamp\n",
    "              self.producer.flush()\n",
    "        \n",
    "        self.start_time = last\n",
    "\n",
    "        # Wait for more data to be available\n",
    "        time_diff = datetime.utcnow() - datetime.strptime(last, self.format_str)\n",
    "        time_diff_sec = time_diff.total_seconds()\n",
    "\n",
    "        if time_diff_sec < self.buffer:\n",
    "          wait_time = self.buffer - time_diff_sec\n",
    "          if wait_time > 0:\n",
    "            time.sleep(wait_time)\n",
    "          else:\n",
    "            time.sleep(1)\n",
    "\n",
    "        self.end_time = datetime.utcnow().strftime(self.format_str)\n",
    "    except Exception as e:\n",
    "      self.producer.close()\n",
    "      raise RuntimeError(e)\n",
    "\n",
    "  \n",
    "  async def _async_feed_stream(self):\n",
    "\n",
    "    if not self.aio_producer:\n",
    "      self.aio_producer = aiokafka.AIOKafkaProducer(\n",
    "        bootstrap_servers=self.kafka_server, \n",
    "        value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8'),\n",
    "        key_serializer=lambda k: k.encode('utf-8'),\n",
    "        loop=asyncio.get_event_loop()\n",
    "      )\n",
    "\n",
    "    self.is_running = True\n",
    "    last = None\n",
    "    \n",
    "    async with self.aio_producer:\n",
    "\n",
    "      while self.is_running:\n",
    "        # Set data interval\n",
    "        intervals = self._break_time_range(self.start_time, self.end_time)\n",
    "\n",
    "        futures = []\n",
    "        timestamps = []\n",
    "\n",
    "        # Get data for the interval\n",
    "        for interval in intervals:\n",
    "          data = self._get_data(interval[0], interval[1])\n",
    "          for row in data:\n",
    "            event = self._transform_data(row)\n",
    "            event_timestamp = event['Timestamp'].strftime(self.format_str)\n",
    "            max_timestamp = max(timestamps) if len(timestamps) > 0 else last\n",
    "            if not last or event_timestamp > max_timestamp:\n",
    "              future = self.aio_producer.send(self.kafka_topic, key=event_timestamp, value=event)\n",
    "              futures.append(future)\n",
    "              timestamps.append(event_timestamp)\n",
    "\n",
    "        last = max(timestamps) if len(timestamps) > 0 else last\n",
    "        self.start_time = last\n",
    "        logging.info(self.start_time)\n",
    "\n",
    "        await asyncio.gather(*futures)\n",
    "        await self.aio_producer.flush()\n",
    "\n",
    "        # Wait for more data to be available\n",
    "        time_diff = datetime.utcnow() - datetime.strptime(last, self.format_str)\n",
    "        time_diff_sec = time_diff.total_seconds()\n",
    "\n",
    "        if time_diff_sec < self.buffer:\n",
    "          wait_time = self.buffer - time_diff_sec\n",
    "          if wait_time > 0:\n",
    "            time.sleep(wait_time)\n",
    "          else:\n",
    "            time.sleep(1)\n",
    "\n",
    "        self.end_time = datetime.utcnow().strftime(self.format_str)\n",
    "\n",
    "  def start(self):\n",
    "    if self.mode == 'sync':\n",
    "      self._feed_stream()\n",
    "    else:\n",
    "      loop = asyncio.new_event_loop()\n",
    "      asyncio.set_event_loop(loop)\n",
    "      try:\n",
    "        loop.run_until_complete(self._async_feed_stream())\n",
    "      finally:\n",
    "        loop.close()\n",
    "    logging.info(\"Producer started.\")\n",
    "\n",
    "  def stop(self):\n",
    "    self.is_running = False\n",
    "    if self.mode == 'sync':\n",
    "      self.producer.close()\n",
    "    else:\n",
    "      self.aio_producer.close()\n",
    "    \n",
    "  def status(self):\n",
    "    return self.is_running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "\n",
    "url = f'https://api.exchange.coinbase.com/products/BTC-USD/candles?granularity=60&start=2024-12-16 00:00:00&end=2024-12-16 01:18:45'\n",
    "r.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CryptoProducer('btc', 'localhost:9094', '2024-12-16 00:00:00', None, 60, 'BTC-USD').start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
